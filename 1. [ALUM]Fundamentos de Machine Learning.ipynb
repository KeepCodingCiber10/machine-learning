{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Fundamentos de *Machine Learning*\n",
    "\n",
    "En este notebook se revisarán los conceptos de:\n",
    "\n",
    "1. Notación\n",
    "2. Vecinos más próximos\n",
    "3. Repaso de Pandas\n",
    "4. Evaluación del modelo: entrenamiento y test\n",
    "5. Selección del modelo: validación cruzada\n",
    "6. Conceptos fundamentales de ML\n",
    "  1. Compromiso sesgo-varianza\n",
    "  2. Curvas de aprendizaje\n",
    "\n",
    "Primero cargamos librerías y funciones necesarias, incluyendo las del módulo `utils`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_decision_boundary, poly_linear_regression, CM_BRIGHT\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Notación\n",
    "\n",
    "Vamos a importar la librería principal de este módulo, scikit-learn. Habitualmente se importa como `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LpD8cDrjanjg"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/automobile.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 227,
     "status": "ok",
     "timestamp": 1626809911122,
     "user": {
      "displayName": "gabriel valverde castilla",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh64D_U8sD_n3dvejLV4I4cYNlVYAtHwuyxiZpUjA=s64",
      "userId": "06087511696152755932"
     },
     "user_tz": -120
    },
    "id": "5AOYLNjLanjh",
    "outputId": "fad04553-c03b-41db-baba-d605ce7bc0ce"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "executionInfo": {
     "elapsed": 384,
     "status": "ok",
     "timestamp": 1626809933039,
     "user": {
      "displayName": "gabriel valverde castilla",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh64D_U8sD_n3dvejLV4I4cYNlVYAtHwuyxiZpUjA=s64",
      "userId": "06087511696152755932"
     },
     "user_tz": -120
    },
    "id": "38E2RksManjm",
    "outputId": "7d25f391-0c5a-43e2-ceb7-51d5fd3609d9"
   },
   "outputs": [],
   "source": [
    "# show the first 5 rows using dataframe.head() method\n",
    "print(\"Las primeras 5 filas del dataframe\") \n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fxxBaZTDanj0",
    "outputId": "27b9776d-f36b-47d5-ef38-0d5bc12b9b56"
   },
   "outputs": [],
   "source": [
    "index = df.index\n",
    "columns = df.columns\n",
    "values = df.values\n",
    "\n",
    "print(type(index))\n",
    "print(type(columns))\n",
    "print(type(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 228,
     "status": "ok",
     "timestamp": 1626810218359,
     "user": {
      "displayName": "gabriel valverde castilla",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh64D_U8sD_n3dvejLV4I4cYNlVYAtHwuyxiZpUjA=s64",
      "userId": "06087511696152755932"
     },
     "user_tz": -120
    },
    "id": "JAsnfNiWanj4",
    "outputId": "35e5a42b-e565-49fe-9711-5dd26f1ac215"
   },
   "outputs": [],
   "source": [
    "df[\"make\"].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w9EK9KBMankB",
    "outputId": "fdd9f7c1-2396-4aa5-b683-4e7a0878c847"
   },
   "outputs": [],
   "source": [
    "df[[\"fuel-system\", \"make\"]].tail(5) # we dont have to follow the original column order when subsetting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 397,
     "status": "ok",
     "timestamp": 1626810523944,
     "user": {
      "displayName": "gabriel valverde castilla",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh64D_U8sD_n3dvejLV4I4cYNlVYAtHwuyxiZpUjA=s64",
      "userId": "06087511696152755932"
     },
     "user_tz": -120
    },
    "id": "S1Epe2_-ankP",
    "outputId": "6a8cd85f-6f43-485f-fccc-1b7a5c278208"
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "executionInfo": {
     "elapsed": 246,
     "status": "ok",
     "timestamp": 1626810528468,
     "user": {
      "displayName": "gabriel valverde castilla",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh64D_U8sD_n3dvejLV4I4cYNlVYAtHwuyxiZpUjA=s64",
      "userId": "06087511696152755932"
     },
     "user_tz": -120
    },
    "id": "4y7BoO94ankQ",
    "outputId": "0b2feb4c-997f-4115-e2af-68578710bff8"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 438
    },
    "executionInfo": {
     "elapsed": 304,
     "status": "ok",
     "timestamp": 1626810544532,
     "user": {
      "displayName": "gabriel valverde castilla",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh64D_U8sD_n3dvejLV4I4cYNlVYAtHwuyxiZpUjA=s64",
      "userId": "06087511696152755932"
     },
     "user_tz": -120
    },
    "id": "yc0S-mT5ankR",
    "outputId": "a192a8c5-6f2c-4fba-b079-c55694640441"
   },
   "outputs": [],
   "source": [
    "# describe all the columns in \"df\" \n",
    "df.describe(include = \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 438
    },
    "executionInfo": {
     "elapsed": 304,
     "status": "ok",
     "timestamp": 1626810544532,
     "user": {
      "displayName": "gabriel valverde castilla",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh64D_U8sD_n3dvejLV4I4cYNlVYAtHwuyxiZpUjA=s64",
      "userId": "06087511696152755932"
     },
     "user_tz": -120
    },
    "id": "yc0S-mT5ankR",
    "outputId": "a192a8c5-6f2c-4fba-b079-c55694640441"
   },
   "outputs": [],
   "source": [
    "# describe returns a df, so we can still perfom operations to all the columns in \"df\" \n",
    "df.describe(include = \"all\").fillna(\"-\")\n",
    "# pandas user guide: https://pandas.pydata.org/docs/user_guide/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos echar un vistazo a los [datasets](http://scikit-learn.org/stable/datasets) de sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "diabetes = datasets.load_diabetes()\n",
    "X = diabetes.data\n",
    "y = diabetes.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO 1.1: Sobre el conjunto de datos anterior, el dataset de diabetes, vamos a calcular los siguientes valores:\n",
    "</div>\n",
    "\n",
    "* $N$: número de muestras\n",
    "* $d$: dimensionalidad del espacio de entrada\n",
    "* $\\mathbf{x}^{(10)}$: muestra $i=10$\n",
    "* $\\mathbf{x}_1$: característica/variable/*feature* $1$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para resolver el problema, vamos a seguir una serie de pasos.\n",
    "# Lo primero es saber a qué nos enfrentamos: qué son x e y?\n",
    "\n",
    "# ... código para analizar qué tipo de datos son X e y\n",
    "print(type(X))\n",
    "print(type(y))\n",
    "\n",
    "# .... código para saber el tamaño (o la forma) de X e y\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# Sabiendo la forma de X deberíamos ser capaces de determinar el número de muestras y la dimensionalidad\n",
    "\n",
    "n = ...\n",
    "d = ...\n",
    "\n",
    "print(f'El numero de muestras es {n} y la dimensionalidad es {d}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En cuanto a la muestra número 10, debemos recordar que Python es zero-indexed\n",
    "\n",
    "# ... código para extraer el décimo elemento en la primera dimensión de X (es decir, las filas)\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para la primera característica, también debemos recordar que Python es zero-indexed\n",
    "\n",
    "# ... código para extraer el primer elemento en la segunda dimensión de X (es decir, las columnas)\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO 1.2: ¿Es un problema de clasificación o de regresión? ¿Por qué?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¿Cómo podríamos determinar si el problema es de regresión o clasificación? ¿Qué es lo que diferencia a uno de otro?\n",
    "\n",
    "# ... código\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresion Lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris(as_frame=True)\n",
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://en.wikipedia.org/wiki/Iris_flower_data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = iris.data\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"type\"] = iris.target\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"type_name\"] = df[\"type\"].map({0:\"Setosa\",1:\"Versicolour\",2:\"Virginica\"})\n",
    "df.columns = [\"sepal_l\", \"sepal_w\", \"petal_l\", \"petal_w\", \"type\", \"type_name\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.scatter(x=\"sepal_l\", y=\"petal_l\",c=\"type\", colormap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "df_plot = df.drop(columns=[\"type\"])\n",
    "sns.pairplot(df_plot, hue=\"type_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df[[\"sepal_l\", \"sepal_w\", \"petal_l\", \"petal_w\"]]\n",
    "y=df[\"type\"]\n",
    "lr = LinearRegression().fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el pairplot\n",
    "g = sns.pairplot(df_plot, hue=\"type_name\", height=2.5)\n",
    "\n",
    "# Función para agregar línea de tendencia\n",
    "def add_trendline(x, y, color, ax):\n",
    "    m, b = np.polyfit(x, y, 1)\n",
    "    ax.plot(x, m*x + b, color=color)\n",
    "\n",
    "# Iterar sobre los subplots del pairplot\n",
    "variables = [\"sepal_l\", \"sepal_w\", \"petal_l\", \"petal_w\"]\n",
    "for i, var1 in enumerate(variables):\n",
    "    for j, var2 in enumerate(variables):\n",
    "        if i != j:  # Evitar la diagonal\n",
    "            ax = g.axes[i, j]\n",
    "            for t, color in zip(df[\"type_name\"].unique(), sns.color_palette()):\n",
    "                data = df[df[\"type_name\"] == t]\n",
    "                add_trendline(data[var2], data[var1], color, ax=ax)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# La regresion polinomica es solamente un caso especial de regresion lineal\n",
    "# Asi que solo tenemos que transformar los datos para adaptarlos a\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "poly_features = poly.fit_transform(X)\n",
    "poly_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2 = LinearRegression().fit(poly_features, y)\n",
    "lr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Crear el pairplot\n",
    "g = sns.pairplot(df_plot, hue=\"type_name\", height=2.5)\n",
    "\n",
    "# Función para agregar línea de tendencia\n",
    "def add_poly_regression(x, y, color, ax, degree):\n",
    "    x_array = x.values.reshape(-1, 1)\n",
    "    \n",
    "    # Crear y ajustar el modelo polinomial\n",
    "    poly_model = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "    poly_model.fit(x_array, y)\n",
    "    \n",
    "    # Generar puntos para la línea suave\n",
    "    x_plot = np.linspace(x.min(), x.max(), 100).reshape(-1, 1)\n",
    "    y_plot = poly_model.predict(x_plot)\n",
    "    \n",
    "    # Dibujar la línea de regresión polinomial\n",
    "    ax.plot(x_plot, y_plot, color=color, alpha=0.8)\n",
    "\n",
    "# Iterar sobre los subplots del pairplot\n",
    "variables = [\"sepal_l\", \"sepal_w\", \"petal_l\", \"petal_w\"]\n",
    "for i, var1 in enumerate(variables):\n",
    "    for j, var2 in enumerate(variables):\n",
    "        if i != j:  # Evitar la diagonal\n",
    "            ax = g.axes[i, j]\n",
    "            for t, color in zip(df[\"type\"].unique(), sns.color_palette()):\n",
    "                data = df[df[\"type\"] == t]\n",
    "                add_poly_regression(data[var2], data[var1], color, ax, degree=2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO: Entrena una regresion de grado 4 y grafica los resultados. Dependiendo de los datos que tengamos, ¿que debemos esperar del modelo que elijamos?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcular Error\n",
    "\n",
    "En sklean es muy sencillo calcular el error de una regresion lineal. Solamente hay que llamar al metodo `.score()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df[[\"sepal_l\", \"sepal_w\", \"petal_l\", \"petal_w\"]]\n",
    "lr.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO: Calcula el error para todas las regresiones polinomicas hasta grado 10, ¿Cual es la regresion con menos error? ¿Que termino parece ser el que mas afecta al error?\n",
    "\n",
    "Por que pasa esto?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "for degree in range(1,11):\n",
    "    # ... code\n",
    "    ...\n",
    "    \n",
    "errors\n",
    "#_ = pd.DataFrame(errors).plot(title=\"Error R2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "def accuracy(y_true_m, y_pred_m):\n",
    "    assert len(y_true_m)==len(y_pred_m), \"Error: Las longitudes no son iguales.\"\n",
    "    correct = np.sum(y_true_m.values == y_pred_m)\n",
    "    return correct/len(y_true_m)\n",
    "\n",
    "\n",
    "lr = LinearRegression().fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "root_mean_squared_error(y_true=y_test, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO: Similar al ejercicio anterior, pero realiza el train/test split y utiliza la metrica RMSE.\n",
    "Que observas esta vez?\n",
    "</div>\n",
    "\n",
    "Nota: Esta vez lo haremos bien. Utiliza `sepal_w, petal_w, petal_l` como `X` y `sepal_l` como `y`. ¿Puedes explicar en que clase de problema nos enfrentamos? ¿Si esto fuera el mundo real, y sabiendo que representa el Iris dataset, que estariamos intentando hacer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... code\n",
    "\n",
    "errors = []\n",
    "for degree in range(1,11):\n",
    "    # ... code\n",
    "    ...\n",
    "\n",
    "errors\n",
    "#_ = pd.DataFrame(errors).plot(title=\"Error RMSE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Vecinos más próximos\n",
    "\n",
    "En este notebook vamos a trabajar con el algoritmo de KNN en distintos problemas de **clasificación**.\n",
    "\n",
    "### 2.1. Medida de las prestaciones de un clasificador\n",
    "\n",
    "Por clasificador entendemos un algoritmo que, a partir de un conjunto de muestras/observaciones de entrenamiento, es capaz de identificar a qué clase (categoría) pertenece una nueva observación.\n",
    "\n",
    "Una métrica de calidad que podemos usar para medir las prestaciones de un clasificador es el **error de clasificación**\n",
    "\n",
    "$$\\textrm{Error} = \\frac{\\textrm{núm de muestras mal clasificadas}}{\\textrm{núm de muestras total del problema}}$$\n",
    "\n",
    "* Ejemplo: problema de clasificación con dos clases $y\\in{0,1}$\n",
    "    * Etiquetas reales (*y_true*) = $[1,0,0,1,0]$\n",
    "    * Etiquetas predichas (*y_pred*) = $[0,0,1,1,0]$\n",
    "    \n",
    "    * En este caso: $$\\textrm{Error} = \\frac{\\textrm{núm de muestras mal clasificadas} = 2}{\\textrm{núm de muestras total del problema} = 5} = \\frac{2}{5} = 0.4$$\n",
    "\n",
    "Así, el error de clasificación será un número entre 0 y 1, tal que:\n",
    "\n",
    "* $\\textrm{Error} = 0$ es el mejor valor posible (no me equivoco nada)\n",
    "* $\\textrm{Error} = 1$ es el peor valor posible (me equivoco en todas las muestras). Nota: si me equivoco en la clasificación de todas las muestras, entonces puedo interpretar que el clasificador es bueno, pero que tengo que hacer justo lo contrario de lo que me dice. El peor valor de error sería por tanto $0.5$, en el que la incertidumbre es mayor. \n",
    "\n",
    "Normalmente no se utiliza el error, sino su complementario, la exactitud o [**accuracy**](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) (Acc):\n",
    "\n",
    "$$\\textrm{Acc} = 1 - \\textrm{Error}$$\n",
    "\n",
    "y entonces:\n",
    "\n",
    "* $\\textrm{Acc} = 1$ es el mejor valor posible (no me equivoco nada)\n",
    "* $\\textrm{Acc} = 0$ es el peor valor posible (me equivoco en todas las muestras)\n",
    "\n",
    "### 2.2 Ejemplos\n",
    "\n",
    "Para analizar el comportamiento del algoritmo de K-NN, utilizaremos tres ejemplos sencillos, como mostraremos a continuación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo1\n",
    "ejemplo1 = pd.read_csv(\"./data/ex2data1.txt\", sep=\",\", header=None, names=['x1', 'x2', 'label'])\n",
    "ejemplo1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 Pequeño desvío: repaso de Pandas\n",
    "\n",
    "Vamos a hacer un pequeño repaso de las funciones más habituales. No toméis esto como un estudio exhaustivo, ni mucho menos; pero grosso modo os servirá para este módulo.\n",
    "\n",
    "Vamos a ver los siguientes métodos:\n",
    "\n",
    "- `.describe()`, que proporciona un pequeño análisis estadístico. El parámetro `include=all` permite añadir variables categóricas\n",
    "- `.shape`\n",
    "- `.head()`\n",
    "- `.tail()`\n",
    "- `.dtypes`\n",
    "- Análisis de valores nulos con `.isnull()` e `.isnull().any()`\n",
    "- Eliminación de columnas con `.drop(c1, axis=1)`\n",
    "- Cómo acceder a los índices internos, con `.index` y `.index.values`\n",
    "- Cómo acceder a un elemento determinado en base a su índice, con `.iloc[[i1, i2, i3, ...]]`\n",
    "- Cómo construir un nuevo dataframe filtrando el anterior, con `df_filtered = df[condición]`\n",
    "- Cómo construir un nuevo dataframe filtrando el anterior bajo condición múltiple, con `df_filtered = df[(condición 1) & (condición 2)]`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ejemplo1\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_drop = df.drop('x1', axis=1)\n",
    "df_to_drop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[[2, 45, 23, 98]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df[(df['x1'] > 45) & (df['x2'] < 60)]\n",
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez estudiado el dataframe, podemos representar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(ejemplo1['x1'], ejemplo1['x2'], c=ejemplo1['label'], cmap=CM_BRIGHT)\n",
    "plt.xlabel(\"$x_1$\", fontsize=16)\n",
    "plt.ylabel(\"$x_2$\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se dice que este problema es **linealmente separable**, porque podemos trazar una recta para separar las dos clases (representadas en distintos colores, rojo y azul).\n",
    "* En el plano bidimensional: recta\n",
    "* En un espacio d-dimensional: hiperplano\n",
    "\n",
    "Nota: No es linealmente separable puesto que la separación no es perfecta. Pero es _casi_ linealmente separable, aceptamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo2\n",
    "ejemplo2 = pd.read_csv(\"./data/ex2data2.txt\", sep=\",\", header=None, names=['x1', 'x2', 'label'])\n",
    "\n",
    "plt.scatter(ejemplo2['x1'], ejemplo2['x2'], c=ejemplo2['label'], cmap=CM_BRIGHT)\n",
    "plt.xlabel(\"$x_1$\", fontsize=16)\n",
    "plt.ylabel(\"$x_2$\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se dice que este problema es **no linealmente separable**, porque no podemos trazar una recta para separar las dos clase (representadas en distintos colores, rojo y azul)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo 3: Problema XOR \n",
    "np.random.seed(0)\n",
    "\n",
    "# -- parameters\n",
    "N     = 800\n",
    "mu    = 1.5      # Cambia este valor\n",
    "sigma = 1      # Cambia este valor\n",
    "\n",
    "# variables auxiliares\n",
    "unos = np.ones(int(N/4))\n",
    "random4 = sigma*np.random.randn(int(N/4),1)\n",
    "random2 = sigma*np.random.randn(int(N/2),1)\n",
    "\n",
    "# -- features\n",
    "y3 = np.concatenate([-1*unos, unos, unos, -1*unos]) \n",
    "X1 = np.concatenate([-mu + random4, mu + random4, -mu + random4, mu + random4])\n",
    "X2 = np.concatenate([+mu + random2, -mu + random2])\n",
    "X3 = np.hstack((X1,X2))\n",
    "\n",
    "plt.scatter(X3[:,0], X3[:,1], c=y3, cmap=CM_BRIGHT)\n",
    "plt.xlabel(\"$x_1$\", fontsize=16)\n",
    "plt.ylabel(\"$x_2$\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al igual que en el caso anterior, este ejemplo tampoco es linealmente separable, y se conoce como problema XOR. La ventaja del problema XOR es que conocemos cuál es la frontera de separación óptima a priori:\n",
    "\n",
    "- Clase 1, color azul: $x_1,x_2 > 0$, y $ x_1,x_2 < 0$ (cuadrantes 1 y 3)\n",
    "- Clase 2, color rojo: $x_1 < 0,  x_2 > 0$, y $x_1 > 0,  x_2 < 0$ (cuadrantes 2 y 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Entrenar el modelo \n",
    "\n",
    "Vamos a entrenar un modelo K-NN (<a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\">documentación</a> aquí) para los distintos ejemplos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Ejemplo 1\n",
    "# preparamos los datos\n",
    "data1 = ejemplo1.values\n",
    "print(f'El tipo de datos es {type(data1)}')\n",
    "X1 = data1[:, 0:2]\n",
    "y1 = data1[:, -1]\n",
    "\n",
    "# creamos el modelo y ajustamos\n",
    "knnModel = KNeighborsClassifier(n_neighbors=10).fit(X1, y1)\n",
    "\n",
    "plot_decision_boundary(X1, y1, knnModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Número de vecinos**\n",
    "\n",
    "Podemos modificar el número de vecinos $k$ del algoritmo k-nn implementado en scikit-learn mediante el parámetro *n_neighbors*. Por defecto, [scikit-learn](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier) toma *n_neighbors* $=5$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO 1.3: Varía el valor de <b>n_neighbors</b>, ¿qué sucede ahora?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnModel = KNeighborsClassifier(n_neighbors=...).fit(X1, y1)\n",
    "plot_decision_boundary(X1, y1, knnModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO 1.4: Aplica el algoritmo K-NN sobre los ejemplos 2 y 3. ¿Qué sucedería si aplicamos sobre estos ejemplos un algoritmo de <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\">regresión logística</a>? ¿Qué pasa si variamos el número de vecinos?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo 2\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "data2 = ejemplo2.values\n",
    "X2 = ...\n",
    "y2 = ...\n",
    "\n",
    "# creamos el modelo y ajustamos\n",
    "knnModel2 = KNeighborsClassifier(n_neighbors=...).fit(X2, y2)\n",
    "\n",
    "plot_decision_boundary(X2, y2, knnModel2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# .... código para crear el modelo y entrenar\n",
    "lrModel = ...\n",
    "plot_decision_boundary(X1, y1, lrModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# .... código para crear el modelo y entrenar\n",
    "lrModel = ...\n",
    "plot_decision_boundary(X2, y2, lrModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo 3\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# ... código para crear el modelo y entrenar\n",
    "knnModel3 = ...\n",
    "\n",
    "plot_decision_boundary(X3, y3, knnModel3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# .... código para crear el modelo y entrenar\n",
    "lrModel3 = ...\n",
    "plot_decision_boundary(X3, y3, lrModel3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos comprobar que las mejores prestaciones se obtienen cuando *n_neighbors=1*, ¿tiene sentido? ¿Estamos midiendo correctamente las prestaciones de este clasificador?\n",
    "\n",
    "# 3. Evaluación del modelo: entrenamiento y test\n",
    "\n",
    "La respuesta es claramente no. Para poder saber cómo de bien se comporta un algoritmo de machine learning, hemos de medir su capacidad de [generalización](https://en.wikipedia.org/wiki/Generalization_error), esto es, las prestaciones en muestras no vistas previamente por el clasificador. Para ello, dividimos el conjunto de datos en dos partes, entrenamiento y test, teniendo en cuenta que:\n",
    "\n",
    "![](./figuras/train_test_set_2d_classification.png)\n",
    "\n",
    "* Utilizamos aproximadamente un 75-80% de las muestras para entrenamiento y un 25-20% para el test (cuidado! depende del tamaño del dataset; si es muy grande, el conjunto de test puede ser un porcentaje menor)\n",
    "* Ambos conjuntos han de representar la población con la misma estadística: \n",
    "    * Randomizar, esto es, reordenar para evitar orden en las muestras. (cuidado series temporales)\n",
    "    * Estratificar con respecto a una variable (normalmente la variable target), para mantener la proporción de la varible target en los conjuntos train/test.\n",
    "\n",
    "sklern nos proporciona una [función](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) para dividir nuestros datos. \n",
    "\n",
    "Vamos a probar con el primer ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(type(X1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size=0.3, shuffle=True)#, random_state=0)\n",
    "\n",
    "print(type(X_train))\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=15).fit(X_train, y_train)\n",
    "\n",
    "plot_decision_boundary(X_test, y_test, knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO 1.5: Sobre la celda anterior, varía el valor de <b>n_neighbors</b>. ¿Para qué valor se obtienen ahora las mejores prestaciones? ¿Qué sucede si eliminamos <b>random_state = 0</b> y ejecutamos varias veces la misma celda para un valor de <b>n_neighbors</b> fijo? ¿Obtenemos las mismas prestaciones?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO 1.6: Calcula las prestaciones del algoritmo K-NN para los ejemplos 2 y 3. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo 2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(..., ..., test_size=0.3, shuffle=True, random_state=0)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=...).fit(X_train, y_train)\n",
    "\n",
    "plot_decision_boundary(X_test, y_test, knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo 3\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(..., ..., test_size=0.3, shuffle=True, random_state=0)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=...).fit(X_train, y_train)\n",
    "\n",
    "plot_decision_boundary(X_test, y_test, knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO 1.7: Vamos a realizar un análisis del parámetro de estratificación, para ver el efecto que tiene en los datos \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Una forma de estudiarlo\n",
    "ejemplo1['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otra forma de estudiarlo\n",
    "np.unique(y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora: cómo haríais el análisis completo?\n",
    "\n",
    "# Porcentaje global\n",
    "print('DISTRIBUCIÓN DEL DATASET ENTERO')\n",
    "y = ejemplo1['label'].values\n",
    "print(f'% ceros en total: {((np.unique(y, return_counts=True)[1][0]/y.shape[0])*100):.2f}')\n",
    "print('\\n')\n",
    "\n",
    "# Sin estratificar\n",
    "print('SIN ESTRATIFICAR')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size = 0.3, shuffle = True)\n",
    "print(f'% ceros en train: {((np.unique(y_train, return_counts=True)[1][0]/y_train.shape[0])*100):.2f}')\n",
    "print(f'% ceros en test: {((np.unique(y_test, return_counts=True)[1][0]/y_test.shape[0])*100):.2f}')\n",
    "print('\\n')\n",
    "      \n",
    "# Estratificando\n",
    "print('ESTRATIFICANDO')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size = 0.3, shuffle = True, stratify=y1)\n",
    "print(f'% ceros en train: {((np.unique(y_train, return_counts=True)[1][0]/y_train.shape[0])*100):.2f}')\n",
    "print(f'% ceros en test: {((np.unique(y_test, return_counts=True)[1][0]/y_test.shape[0])*100):.2f}')\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO 1.8 (AVANZADO): Representa la performance del algoritmo K-NN en entrenamiento y test para distintos valores de <b>n_neighbors</b> (entre 1 y 15), utilizando el ejemplo 3. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X3, y3, test_size = 0.3, shuffle = True, random_state = 0)\n",
    "\n",
    "# inicializamos\n",
    "neighbors = range(1,50)\n",
    "acc_train = []\n",
    "acc_test  = []\n",
    "\n",
    "for n in neighbors:\n",
    "    \n",
    "    # ... código aquí\n",
    "    # pista: lo único que hay que hacer es instanciar el modelo,\n",
    "    # definiendo correctamente el parámetro del número de vecinos,\n",
    "    # y luego hacer `.fit()` sobre los datos de train\n",
    "    \n",
    "    ...\n",
    "    \n",
    "\n",
    "plt.plot(neighbors,acc_train,'b',label='train')\n",
    "plt.plot(neighbors,acc_test,'r',label='test')\n",
    "plt.legend()\n",
    "plt.xlabel('# vecinos')\n",
    "plt.ylabel('ACC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "El número de vecinos que escojamos afecta significativamente a las prestaciones del algoritmo. Este parámetro es un compromiso entre los errores que cometemos (*accuracy*) y la complejidad del modelo (frontera de separación). \n",
    "\n",
    "- Cuanto menor es el número de vecinos, **más compleja** es la frontera de separación, y por tanto mayor será el sobreajuste. Potencialmente empeorará la *accuracy*.\n",
    "- Cuanto mayor es el número de vecinos, **menos compleja** es la frontera de separación y por tanto menor será el sobreajuste. Potencialmente mejorará la *accuracy*.\n",
    "\n",
    "## 3.1 Conclusiones\n",
    "\n",
    "1. Si las muestras de entrenamiento son escasas (ejemplo 1), el error en test puede ser muy variable , dependiendo de las muestras incluidas en el conjunto de entrenamiento y el conjunto de test.\n",
    "\n",
    "2. Las prestaciones (en test), dependen del número de vecinos que determinan la complejidad de la frontera de separación.\n",
    "\n",
    "Teniendo en cuenta 1 y 2, ¿cómo puedo escoger el valor óptimo de *n_neighbors*?\n",
    "\n",
    "\n",
    "# 4. Selección del modelo: validación cruzada\n",
    "\n",
    "La validación cruzada (o cross-validation) consiste en subdivir el conjunto de entrenamiento en $K$ partes iguales, de tal forma que se utilizan $K-1$ para entrenar (ajustar el modelo) y el bloque $k$ restante para evaluar las prestaciones en función de los parámetros libres. Este proceso se repite $K$ veces (hasta que se barren todos los bloques) y los resultados se promedian.\n",
    "\n",
    "Por suerte, no es necesario programar estas subdivisiones, porque scikit-learn tiene un clase que realiza este trabajo por nosotros. Puedes consultarlo [aquí](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html).\n",
    "\n",
    "Vamos a buscar el valor óptimo del número de vecinos utilizando una estrategia 5-fold CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# recordemos que este es nuestro conjunto de datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(X3, y3, test_size = 0.3, shuffle = True, random_state = 0, stratify=y3)\n",
    "\n",
    "nFolds = 5 #scikit-learn los llama splits\n",
    "kf  = StratifiedKFold(n_splits = nFolds, shuffle = True, random_state=0)\n",
    "\n",
    "nVecinos = range(1,16) # [1-15]\n",
    "\n",
    "# inicializamos una matriz de errores, para cada valor de n_neighbors y cada iteración del algoritmo de cross-validation\n",
    "# - tantas filas como número de folds\n",
    "# - tantas columnas como valores de vector del numero de vecinos\n",
    "accMatriz = np.zeros((nFolds,len(nVecinos))) \n",
    "\n",
    "j = 0 # inicializamos contador de columnas\n",
    "for n in nVecinos:\n",
    "       \n",
    "    knn = KNeighborsClassifier(n_neighbors = n)\n",
    "    \n",
    "    i = 0 # inicializamos contador de filas\n",
    "    for idxTrain, idxVal in kf.split(X_train,y_train):\n",
    "      \n",
    "        Xt = X_train[idxTrain,:]\n",
    "        yt = y_train[idxTrain]\n",
    "        Xv = X_train[idxVal,:]\n",
    "        yv = y_train[idxVal]\n",
    "        \n",
    "        knn.fit(Xt,yt)\n",
    "        accMatriz[i,j] = knn.score(Xv, yv) \n",
    "        \n",
    "        i+=1\n",
    "    j+=1\n",
    "\n",
    "accVector = np.mean(accMatriz,axis=0)\n",
    "accStd = np.std(accMatriz,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos el valor óptimo\n",
    "idx = np.argmax(accVector)\n",
    "nOpt = nVecinos[idx]\n",
    "\n",
    "plt.plot(nVecinos,accVector,'-o')\n",
    "plt.plot(nVecinos[idx],accVector[idx],'rs')\n",
    "plt.title('El número óptimo de vecinos es: %d' % nOpt)\n",
    "plt.xlabel('# vecinos')\n",
    "plt.ylabel('5-Fold ACC')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representemos ahora la gráfica anterior con la variación (desviación estándar) de la *accuracy* en cada *fold*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(nVecinos,accVector,'-o')\n",
    "plt.plot(nVecinos[idx],accVector[idx],'rs')\n",
    "plt.errorbar(nVecinos, accVector, yerr=accStd, ecolor='g')\n",
    "plt.title('El número óptimo de vecinos es: %d' % nOpt)\n",
    "plt.xlabel('# vecinos')\n",
    "plt.ylabel('5-Fold ACC')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Damos las prestaciones reales del modelo (en test)\n",
    "knn = KNeighborsClassifier(n_neighbors = 15)\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "print(\"accuracy: {:.2f}\".format(knn.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El código anterior se puede reducir drásticamente si utilizamos [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html). Pido perdón por el susto.\n",
    "\n",
    "El código de la siguiente celda es equivalente al de las cuatro celdas anteriores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X3, y3, test_size = 0.3, shuffle = True, random_state = 0)\n",
    "\n",
    "param_grid = {'n_neighbors':  np.arange(1, 16, 1)}\n",
    "grid = GridSearchCV(KNeighborsClassifier(), scoring= 'accuracy', param_grid=param_grid, cv = 5, verbose=1).fit(X_train, y_train)\n",
    "print(\"best mean cross-validation score: {:.3f}\".format(grid.best_score_))\n",
    "print(\"best parameters: {}\".format(grid.best_params_))\n",
    "\n",
    "scores = np.array(grid.cv_results_['mean_test_score']) #¡cuidado, lo llaman test cuando es validación!\n",
    "stdvalues = np.array(grid.cv_results_['std_test_score'])\n",
    "plt.plot(np.arange(1, 16, 1),scores,'-o')\n",
    "plt.errorbar(nVecinos, scores, yerr=stdvalues, ecolor='g')\n",
    "plt.xlabel('# vecinos')\n",
    "plt.ylabel('5-Fold ACC')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "print(\"acc (test): {:.2f}\".format(grid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referencias\n",
    "\n",
    "1. Capítulo 2. An Introduction to Statistical Learning. \n",
    "2. [Bias–variance tradeoff](https://en.wikipedia.org/wiki/Bias–variance_tradeoff)\n",
    "3. [Underfitting and overfitting, scikit learn docs](http://scikit-learn.org/stable/auto_examples/model_selection/plot_underfitting_overfitting.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio final del tema\n",
    "\n",
    "Aplica lo que has aprendido en un dataset de cyberseguridad. Vamos a utilizar para ello un dataset de deteccion de spam en correo electronico. En el dataset, cada fila corresponde con el analisis textual de un email en la bandeja de entrada de un empleado.\n",
    "\n",
    " - Analiza que tiene el dataset. Cuantas filas? Cuantas columnas? Cual es la variable objetivo? Que significa cada columna?\n",
    " - Que tipo de problema es? Clasificacion o regresion? Por que?\n",
    " - En base al tipo de problema detectado, elige un modelo de ML para entrenarlo sobre los datos.\n",
    " - Elige una metrica que tenga sentido para este problema.\n",
    " - Haz un split de los datos para el entrenamiento.\n",
    " - Entrena el modelo.\n",
    " - Evalua que tal ha ido el entrenamiento con la metrica que has utilizado.\n",
    " - Explica que significa el valor de la metrica obtenida a un niño de 5 años.\n",
    " - Usa el modelo entrenado para predecir sobre datos que no ha visto nunca (df_realWorld), tienen sentido las predicciones? Como puedes estar seguro?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000</td>\n",
       "      <td>15</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.450</td>\n",
       "      <td>11</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.729</td>\n",
       "      <td>43</td>\n",
       "      <td>749</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0            0.00               0.00           0.00           0.0   \n",
       "1            0.00               0.00           0.00           0.0   \n",
       "2            0.00               0.00           0.00           0.0   \n",
       "3            0.00               0.00           0.00           0.0   \n",
       "4            0.06               0.12           0.77           0.0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0           0.63            0.00              0.31                0.63   \n",
       "1           0.63            0.00              0.31                0.63   \n",
       "2           1.85            0.00              0.00                1.85   \n",
       "3           1.88            0.00              0.00                1.88   \n",
       "4           0.19            0.32              0.38                0.00   \n",
       "\n",
       "   word_freq_order  word_freq_mail  ...  char_freq_;  char_freq_(  \\\n",
       "0             0.31            0.63  ...         0.00        0.137   \n",
       "1             0.31            0.63  ...         0.00        0.135   \n",
       "2             0.00            0.00  ...         0.00        0.223   \n",
       "3             0.00            0.00  ...         0.00        0.206   \n",
       "4             0.06            0.00  ...         0.04        0.030   \n",
       "\n",
       "   char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
       "0          0.0        0.137        0.000          0.0   \n",
       "1          0.0        0.135        0.000          0.0   \n",
       "2          0.0        0.000        0.000          0.0   \n",
       "3          0.0        0.000        0.000          0.0   \n",
       "4          0.0        0.244        0.081          0.0   \n",
       "\n",
       "   capital_run_length_average  capital_run_length_longest  \\\n",
       "0                       3.537                          40   \n",
       "1                       3.537                          40   \n",
       "2                       3.000                          15   \n",
       "3                       2.450                          11   \n",
       "4                       1.729                          43   \n",
       "\n",
       "   capital_run_length_total  spam  \n",
       "0                       191     1  \n",
       "1                       191     1  \n",
       "2                        54     1  \n",
       "3                        49     1  \n",
       "4                       749     1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/spam.csv')\n",
    "df_realWorld = pd.read_csv('data/spam_realWorld.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
